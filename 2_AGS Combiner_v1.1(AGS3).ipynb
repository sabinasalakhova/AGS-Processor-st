{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_from_to(file):\n",
    "    \"\"\"\n",
    "    Creates from to file from the combined excel database of boreholes.\n",
    "    Accepts excel ONLY.\n",
    "    \"\"\"\n",
    "    df=pd.read_excel(file)\n",
    "    HOLE_ID = df.HOLE_ID.values # Which BH(s) would you like to process?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Initializing: import modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#Initializing: define data checking functions\n",
    "def check_second_row(df):\n",
    "    \"\"\"\n",
    "    Checks and removes if the sheet has <UNIT> row.\n",
    "    \"\"\"\n",
    "    if df.HOLE_ID[0] == ('<UNITS>' or '<UNIT>'):\n",
    "        df = df.drop([0])\n",
    "    return df\n",
    "\n",
    "def clean_geol_cont(GEOL):\n",
    "    \"\"\"\n",
    "    Checks and cleans if the GEOL sheet contains <CONT> rows.\n",
    "    \"\"\"\n",
    "    i=0    #Resets initial index\n",
    "    for i in range(len(GEOL)):\n",
    "        if GEOL.HOLE_ID[i] == '<CONT>':\n",
    "            GEOL.GEOL_DESC[i-1] = GEOL.GEOL_DESC[i-1]+' '+GEOL.GEOL_DESC[i]\n",
    "            GEOL.GEOL_LEG[i-1] = GEOL.GEOL_LEG[i]\n",
    "            GEOL.GEOL_STAT[i-1] = GEOL.GEOL_STAT[i]\n",
    "            GEOL = GEOL.drop([i])\n",
    "    return GEOL\n",
    "\n",
    "def clean_hole_cont(HOLE):\n",
    "    \"\"\"\n",
    "    Checks and cleans if the HOLE sheet contains <CONT> rows.\n",
    "    \"\"\"\n",
    "    i=0    #Resets initial index\n",
    "    for i in range(len(GEOL)):\n",
    "        if GEOL.HOLE_ID[i] == '<CONT>':\n",
    "            HOLE.HOLE_REM[i-1] = HOLE.HOLE_REM[i-1]+' '+HOLE.HOLE_REM[i]\n",
    "            HOLE.HOLE_ORNT[i-1] = HOLE.HOLE_ORNT[i]\n",
    "            HOLE.HOLE_INCL[i-1] = HOLE.HOLE_INCL[i]\n",
    "            HOLE = HOLE.drop([i])\n",
    "    return HOLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 1.1: Reads different tabs of the excel file created from AGS as different DataFrames\n",
    "'''\n",
    "\n",
    "## Optional part for combining survey data for 66917, 66917\n",
    "#HORN = pd.read_excel('66917-AGS.xlsx', sheet_name='%%dHORN')\n",
    "#HORN = check_second_row(HORN)\n",
    "\n",
    "\n",
    "concat_file = 'Concat_data_combined.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "## Compulsory:\n",
    "data = {}\n",
    "for sheet in ['HOLE', 'CORE', 'DETL', 'WETH', 'FRAC', 'GEOL']:\n",
    "    data[sheet] = pd.read_excel(concat_file, sheet_name=sheet)\n",
    "    data[sheet]['HOLE_ID'] = np.where(\n",
    "        data[sheet]['AGS_REP'].str[:5].str.contains('[a-zA-Z]', na=False),\n",
    "        data[sheet]['HOLE_ID'], # Value if condition is True (contains letters)\n",
    "        data[sheet]['AGS_REP'].str[:5] + \"_\" + data[sheet]['HOLE_ID']) # Value if condition is False (no letters)\n",
    "    sheet = check_second_row(data[sheet])\n",
    "\n",
    "if '<CONT>' in data['GEOL'].HOLE_ID.values:  \n",
    "    GEOL = clean_geol_cont(data['GEOL'])\n",
    "\n",
    "CORE = data['CORE'] \n",
    "DETL = data['DETL']\n",
    "WETH = data['WETH']\n",
    "FRAC = data['FRAC']\n",
    "GEOL = data['GEOL']\n",
    "HOLE = data['HOLE']\n",
    "\n",
    "#HOLE_ID = HOLE.HOLE_ID.values\n",
    "filtered = HOLE[HOLE['Include'] >= 1]\n",
    "HOLE_ID = filtered.HOLE_ID.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "942\n"
     ]
    }
   ],
   "source": [
    "print(len(HOLE_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 942/942 [10:46<00:00,  1.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOLE_ID</th>\n",
       "      <th>DEPTH_FROM</th>\n",
       "      <th>DEPTH_TO</th>\n",
       "      <th>GEOL</th>\n",
       "      <th>GEOL_DESC</th>\n",
       "      <th>THICKNESS_M</th>\n",
       "      <th>TCR</th>\n",
       "      <th>RQD</th>\n",
       "      <th>NR</th>\n",
       "      <th>Mod_Weak</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil</th>\n",
       "      <th>Jn</th>\n",
       "      <th>Jr_Max</th>\n",
       "      <th>Jr_Min</th>\n",
       "      <th>Ja_Max</th>\n",
       "      <th>Ja_Min</th>\n",
       "      <th>Jw</th>\n",
       "      <th>SRF</th>\n",
       "      <th>Q'</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NOL-1631-DH01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FILL</td>\n",
       "      <td>Firm, brown, slightly clayey SILT with occasio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NOL-1631-DH01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>CLAYZ</td>\n",
       "      <td>Soft, light brown, slightly silty CLAY (ALLUVIUM)</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOL-1631-DH01</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>SILTCS</td>\n",
       "      <td>Firm, light brown, slightly clayey SILT with o...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NOL-1631-DH01</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>SILTC</td>\n",
       "      <td>Extremely weak, light brown, spotted white, co...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NOL-1631-DH01</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>SILTC</td>\n",
       "      <td>Extremely weak, light brown, spotted white, co...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37253</th>\n",
       "      <td>68240_BH 5</td>\n",
       "      <td>34.63</td>\n",
       "      <td>35.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderately strong, red spotted black and white...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>96.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37254</th>\n",
       "      <td>68240_BH 5</td>\n",
       "      <td>35.11</td>\n",
       "      <td>35.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderately strong, red spotted black and white...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37255</th>\n",
       "      <td>68240_BH 5</td>\n",
       "      <td>35.54</td>\n",
       "      <td>35.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderately strong, red spotted black and white...</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37256</th>\n",
       "      <td>68240_BH 5</td>\n",
       "      <td>35.69</td>\n",
       "      <td>35.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderately strong, red spotted black and white...</td>\n",
       "      <td>0.27</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37257</th>\n",
       "      <td>68240_BH 5</td>\n",
       "      <td>35.96</td>\n",
       "      <td>36.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Moderately strong, red spotted black and white...</td>\n",
       "      <td>0.37</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37258 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             HOLE_ID DEPTH_FROM DEPTH_TO    GEOL  \\\n",
       "0      NOL-1631-DH01        0.0      1.0    FILL   \n",
       "1      NOL-1631-DH01        1.0      2.5   CLAYZ   \n",
       "2      NOL-1631-DH01        2.5      3.6  SILTCS   \n",
       "3      NOL-1631-DH01        3.6      5.6   SILTC   \n",
       "4      NOL-1631-DH01        5.6      7.6   SILTC   \n",
       "...              ...        ...      ...     ...   \n",
       "37253     68240_BH 5      34.63    35.11     NaN   \n",
       "37254     68240_BH 5      35.11    35.54     NaN   \n",
       "37255     68240_BH 5      35.54    35.69     NaN   \n",
       "37256     68240_BH 5      35.69    35.96     NaN   \n",
       "37257     68240_BH 5      35.96    36.33     NaN   \n",
       "\n",
       "                                               GEOL_DESC THICKNESS_M    TCR  \\\n",
       "0      Firm, brown, slightly clayey SILT with occasio...         1.0    NaN   \n",
       "1      Soft, light brown, slightly silty CLAY (ALLUVIUM)         1.5    NaN   \n",
       "2      Firm, light brown, slightly clayey SILT with o...         1.1    NaN   \n",
       "3      Extremely weak, light brown, spotted white, co...         2.0    NaN   \n",
       "4      Extremely weak, light brown, spotted white, co...         2.0    NaN   \n",
       "...                                                  ...         ...    ...   \n",
       "37253  Moderately strong, red spotted black and white...        0.48   96.0   \n",
       "37254  Moderately strong, red spotted black and white...        0.43  100.0   \n",
       "37255  Moderately strong, red spotted black and white...        0.15  100.0   \n",
       "37256  Moderately strong, red spotted black and white...        0.27  100.0   \n",
       "37257  Moderately strong, red spotted black and white...        0.37  100.0   \n",
       "\n",
       "        RQD   NR Mod_Weak  ... Soil   Jn Jr_Max Jr_Min Ja_Max Ja_Min   Jw  \\\n",
       "0       NaN  NaN      NaN  ...  NaN  NaN    NaN    NaN    NaN    NaN  NaN   \n",
       "1       NaN  NaN      NaN  ...  NaN  NaN    NaN    NaN    NaN    NaN  NaN   \n",
       "2       NaN  NaN      NaN  ...  NaN  NaN    NaN    NaN    NaN    NaN  NaN   \n",
       "3       NaN  NaN      NaN  ...  NaN  NaN    NaN    NaN    NaN    NaN  NaN   \n",
       "4       NaN  NaN      NaN  ...  NaN  NaN    NaN    NaN    NaN    NaN  NaN   \n",
       "...     ...  ...      ...  ...  ...  ...    ...    ...    ...    ...  ...   \n",
       "37253  70.0  NaN      NaN  ...  NaN  NaN    NaN    NaN    NaN    NaN  NaN   \n",
       "37254  74.0  NaN      NaN  ...  NaN  NaN    NaN    NaN    NaN    NaN  NaN   \n",
       "37255  74.0  NaN      NaN  ...  NaN  NaN    NaN    NaN    NaN    NaN  NaN   \n",
       "37256  74.0  NaN      NaN  ...  NaN  NaN    NaN    NaN    NaN    NaN  NaN   \n",
       "37257  74.0  NaN      NaN  ...  NaN  NaN    NaN    NaN    NaN    NaN  NaN   \n",
       "\n",
       "       SRF   Q'    Q  \n",
       "0      NaN  NaN  NaN  \n",
       "1      NaN  NaN  NaN  \n",
       "2      NaN  NaN  NaN  \n",
       "3      NaN  NaN  NaN  \n",
       "4      NaN  NaN  NaN  \n",
       "...    ...  ...  ...  \n",
       "37253  NaN  NaN  NaN  \n",
       "37254  NaN  NaN  NaN  \n",
       "37255  NaN  NaN  NaN  \n",
       "37256  NaN  NaN  NaN  \n",
       "37257  NaN  NaN  NaN  \n",
       "\n",
       "[37258 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "'''\n",
    "Step 2: Creates a master DataFrame, assigns the column headings and put information into it\n",
    "'''\n",
    "\n",
    "df=pd.DataFrame(columns=['HOLE_ID','DEPTH_FROM','DEPTH_TO','GEOL','GEOL_DESC','THICKNESS_M','TCR','RQD','NR','Mod_Weak',\n",
    "                         'Weak','Ext_Weak','WETH_GRAD','FI','Details','Fault','Corestone','Breccia','Soil','Jn','Jr_Max',\n",
    "                         'Jr_Min','Ja_Max','Ja_Min','Jw','SRF',\"Q'\",'Q'],index=[0])\n",
    "\n",
    "\n",
    "row_index = 0                                #Creates an accumulating index for recursive input to dataframe\n",
    "for bh in tqdm(range(len(HOLE_ID))):\n",
    "    #=====PART 1: getting combined from/to=====\n",
    "    #getting a sorted union of all depths\n",
    "    all_depths=[]\n",
    "    depth_from=[]\n",
    "    depth_to=[]\n",
    "    all_depths.append(list(CORE[CORE['HOLE_ID']==HOLE_ID[bh]]['CORE_TOP'].values))\n",
    "    all_depths.append(list(CORE[CORE['HOLE_ID']==HOLE_ID[bh]]['CORE_BOT'].values))\n",
    "    all_depths.append(list(DETL[DETL['HOLE_ID']==HOLE_ID[bh]]['DETL_TOP'].values))\n",
    "    all_depths.append(list(DETL[DETL['HOLE_ID']==HOLE_ID[bh]]['DETL_BASE'].values))\n",
    "    all_depths.append(list(WETH[WETH['HOLE_ID']==HOLE_ID[bh]]['WETH_TOP'].values))\n",
    "    all_depths.append(list(WETH[WETH['HOLE_ID']==HOLE_ID[bh]]['WETH_BASE'].values))\n",
    "    all_depths.append(list(FRAC[FRAC['HOLE_ID']==HOLE_ID[bh]]['FRAC_TOP'].values))\n",
    "    all_depths.append(list(FRAC[FRAC['HOLE_ID']==HOLE_ID[bh]]['FRAC_BASE'].values))\n",
    "    all_depths.append(list(GEOL[GEOL['HOLE_ID']==HOLE_ID[bh]]['GEOL_TOP'].values))\n",
    "    all_depths.append(list(GEOL[GEOL['HOLE_ID']==HOLE_ID[bh]]['GEOL_BASE'].values))\n",
    "        \n",
    "        ## Optional:\n",
    "    #    all_depths.append(list(HORN[HORN['HOLE_ID']==HOLE_ID[bh]]['HORN_TOP'].values))\n",
    "    #    all_depths.append(list(HORN[HORN['HOLE_ID']==HOLE_ID[bh]]['HORN_BASE'].values))\n",
    "    \n",
    "    depths=list(set().union(*all_depths))\n",
    "    depths.sort()\n",
    "    depth = [x for x in depths if str(x) != 'nan']   # Removes NaN values from the sorted depths list\n",
    "    depth.sort()\n",
    "    #create a \"from and to\" from this list\n",
    "    depth_from=depth[0:-1]\n",
    "    depth_to=depth[1:]\n",
    "\n",
    "    #=====PART 2: filling in data into the dataframe=====\n",
    "    #filling the from/to into the master DF\n",
    "    d = 0\n",
    "    for d in range(len(depth_to)):\n",
    "        df.loc[row_index,'HOLE_ID'] = HOLE_ID[bh]\n",
    "        df.loc[row_index,'DEPTH_FROM'] = depth_from[d]\n",
    "        df.loc[row_index,'DEPTH_TO'] = depth_to[d]\n",
    "        df.loc[row_index,'THICKNESS_M'] = depth_to[d]-depth_from[d]\n",
    "        row_index=row_index+1\n",
    "    \n",
    "    #filling from WETH sheet\n",
    "    for w in range(0,len(list(WETH[WETH['HOLE_ID']==HOLE_ID[bh]]['WETH_TOP']))):\n",
    "        weth = WETH.loc[(WETH['HOLE_ID']== HOLE_ID[bh])]\n",
    "        df.loc[(df.HOLE_ID==HOLE_ID[bh])&(df.DEPTH_FROM.between(weth.iloc[w]['WETH_TOP'],weth.iloc[w]['WETH_BASE']-.001)),\n",
    "               'WETH_GRAD'] = weth.iloc[w]['WETH_GRAD']\n",
    "    \n",
    "    #filling from GEOL sheet\n",
    "    for g in range(0,len(list(GEOL[GEOL['HOLE_ID']==HOLE_ID[bh]]['GEOL_TOP']))):\n",
    "        geol = GEOL.loc[(GEOL['HOLE_ID']== HOLE_ID[bh])]\n",
    "        df.loc[(df.HOLE_ID==HOLE_ID[bh])&(df.DEPTH_FROM.between(geol.iloc[g]['GEOL_TOP'],geol.iloc[g]['GEOL_BASE']-.001)),\n",
    "               'GEOL'] = geol.iloc[g]['GEOL_LEG']\n",
    "        df.loc[(df.HOLE_ID==HOLE_ID[bh])&(df.DEPTH_FROM.between(geol.iloc[g]['GEOL_TOP'],geol.iloc[g]['GEOL_BASE']-.001)),\n",
    "               'GEOL_DESC'] = geol.iloc[g]['GEOL_DESC']\n",
    "    \n",
    "    #filling from DETL sheet\n",
    "    for d in range(0,len(list(DETL[DETL['HOLE_ID']==HOLE_ID[bh]]['DETL_TOP']))):\n",
    "        detl = DETL.loc[(DETL['HOLE_ID']== HOLE_ID[bh])]\n",
    "        df.loc[(df.HOLE_ID==HOLE_ID[bh])&(df.DEPTH_FROM.between(detl.iloc[d]['DETL_TOP'],detl.iloc[d]['DETL_BASE']-.001)),\n",
    "               'Details'] = detl.iloc[d]['DETL_DESC']\n",
    "    \n",
    "    #filling from CORE sheet\n",
    "    for c in range(0,len(list(CORE[CORE['HOLE_ID']==HOLE_ID[bh]]['CORE_TOP']))):\n",
    "        core = CORE.loc[(CORE['HOLE_ID']== HOLE_ID[bh])]\n",
    "        df.loc[(df.HOLE_ID==HOLE_ID[bh])&(df.DEPTH_FROM.between(core.iloc[c]['CORE_TOP'],core.iloc[c]['CORE_BOT']-.001)),\n",
    "               'RQD'] = core.iloc[c]['CORE_RQD']\n",
    "        df.loc[(df.HOLE_ID==HOLE_ID[bh])&(df.DEPTH_FROM.between(core.iloc[c]['CORE_TOP'],core.iloc[c]['CORE_BOT']-.001)),\n",
    "               'TCR'] = core.iloc[c]['CORE_PREC']\n",
    "    \n",
    "    #filling from FRAC sheet\n",
    "    for fr in range(1,len(list(FRAC[FRAC['HOLE_ID']==HOLE_ID[bh]]['FRAC_TOP']))):\n",
    "        frac = FRAC.loc[(FRAC['HOLE_ID']== HOLE_ID[bh])]\n",
    "        df.loc[(df.HOLE_ID==HOLE_ID[bh])&(df.DEPTH_FROM.between(frac.iloc[fr]['FRAC_TOP'],frac.iloc[fr]['FRAC_BASE']-.001)),\n",
    "               'FI'] = frac.iloc[fr]['FRAC_FI']\n",
    "\n",
    "    ## Optional: filling from HORN sheet\n",
    "#    for h in range(0,len(list(HORN[HORN['HOLE_ID']==HOLE_ID[bh]]['HORN_TOP']))):\n",
    "#        horn = HORN.loc[(HORN['HOLE_ID']== HOLE_ID[bh])]\n",
    "#        df.loc[(df.HOLE_ID==HOLE_ID[bh])&(df.DEPTH_FROM.between(horn.iloc[h]['HORN_TOP'],horn.iloc[h]['HORN_BASE']-.001)),\n",
    "#               'HORN'] = horn.iloc[h]['HORN']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\regine.tsui\\AppData\\Local\\Temp\\13\\ipykernel_31884\\3487473668.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Mod_Weak'].fillna(False,inplace=True)\n",
      "C:\\Users\\regine.tsui\\AppData\\Local\\Temp\\13\\ipykernel_31884\\3487473668.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Weak'].fillna(False,inplace=True)\n",
      "C:\\Users\\regine.tsui\\AppData\\Local\\Temp\\13\\ipykernel_31884\\3487473668.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Ext_Weak'].fillna(False,inplace=True)\n",
      "C:\\Users\\regine.tsui\\AppData\\Local\\Temp\\13\\ipykernel_31884\\3487473668.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['NR'].fillna(False,inplace=True)\n",
      "C:\\Users\\regine.tsui\\AppData\\Local\\Temp\\13\\ipykernel_31884\\3487473668.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Fault'].fillna(False,inplace=True)\n",
      "C:\\Users\\regine.tsui\\AppData\\Local\\Temp\\13\\ipykernel_31884\\3487473668.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Corestone'].fillna(False,inplace=True)\n",
      "C:\\Users\\regine.tsui\\AppData\\Local\\Temp\\13\\ipykernel_31884\\3487473668.py:28: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Breccia'].fillna(False,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Step 3: Key info extraction and interpretation\n",
    "'''\n",
    "\n",
    "#Step 3.1: Get \"weak\"s from dataframe\n",
    "df['Mod_Weak'] = (df['Details'].str.contains('moderately weak', case = False, na = False))|(df['GEOL_DESC'].str.contains(\n",
    "    'moderately weak', case = False))\n",
    "df['Mod_Weak'].fillna(False,inplace=True)\n",
    "df['Weak'] = (df['Details'].str.contains('weak', case = False, na = False))|(df['GEOL_DESC'].str.contains('weak', \n",
    "                                                                                                          case = False))\n",
    "df['Weak'].fillna(False,inplace=True)\n",
    "df['Ext_Weak'] = (df['Details'].str.contains('extremely weak', case = False, na = False))|(df['GEOL_DESC'].str.contains(\n",
    "    'extremely weak', case = False))\n",
    "df['Ext_Weak'].fillna(False,inplace=True)\n",
    "df['NR'] = (df['Details'].str.contains('no recovery', case = False, na = False))|(df['GEOL_DESC'].str.contains(\n",
    "    'no recovery',case = False))\n",
    "df['NR'].fillna(False,inplace=True)\n",
    "\n",
    "#Catch special words from descriptions\n",
    "df['Fault'] = (df['Details'].str.contains('fault', case = False, na = False))|(df['GEOL_DESC'].str.contains('fault', \n",
    "                                                                                                            case = False))\n",
    "df['Fault'].fillna(False,inplace=True)\n",
    "df['Corestone'] = (df['Details'].str.contains('corestone', case = False, na = False))|(df['GEOL_DESC'].str.contains(\n",
    "    'corestone',case = False))\n",
    "df['Corestone'].fillna(False,inplace=True)\n",
    "df['Breccia'] = (df['Details'].str.contains('breccia', case = False, na = False))|(df['GEOL_DESC'].str.contains('breccia', \n",
    "                                                                                                                case = False))\n",
    "df['Breccia'].fillna(False,inplace=True)\n",
    "\n",
    "#Step 3.2: Search for soil stratum\n",
    "\n",
    "## Top Soils (clay, fines, silt, sand only)\n",
    "df.loc[(df['GEOL'].str.contains('CLAY', case = True))&(df['GEOL_DESC'].str.contains('TOPSOIL',\n",
    "                                                                                    case = True)),'Soil']='TS-c'\n",
    "df.loc[(df['GEOL'].str.contains('FINE', case = True))&(df['GEOL_DESC'].str.contains('TOPSOIL',\n",
    "                                                                                    case = True)),'Soil']='TS-c/z'\n",
    "df.loc[(df['GEOL'].str.contains('SILT', case = True))&(df['GEOL_DESC'].str.contains('TOPSOIL',\n",
    "                                                                                    case = True)),'Soil']='TS-z'\n",
    "df.loc[(df['GEOL'].str.contains('SAND', case = True))&(df['GEOL_DESC'].str.contains('TOPSOIL',\n",
    "                                                                                    case = True)),'Soil']='TS-s'\n",
    "\n",
    "## Marine Deposit (clay, fines, silt, sand, gravel, cbbl(?))\n",
    "df.loc[(df['GEOL'].str.contains('CLAY', case = True))&(df['GEOL_DESC'].str.contains('MARINE DEPOSIT',\n",
    "                                                                                    case = True)),'Soil']='MD-c'\n",
    "df.loc[(df['GEOL'].str.contains('FINE', case = True))&(df['GEOL_DESC'].str.contains('MARINE DEPOSIT',\n",
    "                                                                                    case = True)),'Soil']='MD-c/z'\n",
    "df.loc[(df['GEOL'].str.contains('SILT', case = True))&(df['GEOL_DESC'].str.contains('MARINE DEPOSIT',\n",
    "                                                                                    case = True)),'Soil']='MD-z'\n",
    "df.loc[(df['GEOL'].str.contains('SAND', case = True))&(df['GEOL_DESC'].str.contains('MARINE DEPOSIT',\n",
    "                                                                                    case = True)),'Soil']='MD-s'\n",
    "df.loc[(df['GEOL'].str.contains('GRAV', case = True))&(df['GEOL_DESC'].str.contains('MARINE DEPOSIT',\n",
    "                                                                                    case = True)),'Soil']='MD-g'\n",
    "df.loc[(df['GEOL'].str.contains('CBBL', case = True))&(df['GEOL_DESC'].str.contains('MARINE DEPOSIT',\n",
    "                                                                                    case = True)),'Soil']='MD-cb'\n",
    "\n",
    "## Alluvium (clay, fines, silt, sand, gravel, cbbl, boulder)\n",
    "df.loc[(df['GEOL'].str.contains('CLAY', case = True))&(df['GEOL_DESC'].str.contains('ALLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='ALL-c'\n",
    "df.loc[(df['GEOL'].str.contains('FINE', case = True))&(df['GEOL_DESC'].str.contains('ALLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='ALL-c/z'\n",
    "df.loc[(df['GEOL'].str.contains('SILT', case = True))&(df['GEOL_DESC'].str.contains('ALLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='ALL-z'\n",
    "df.loc[(df['GEOL'].str.contains('SAND', case = True))&(df['GEOL_DESC'].str.contains('ALLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='ALL-s'\n",
    "df.loc[(df['GEOL'].str.contains('GRAV', case = True))&(df['GEOL_DESC'].str.contains('ALLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='ALL-g'\n",
    "df.loc[(df['GEOL'].str.contains('CBBL', case = True))&(df['GEOL_DESC'].str.contains('ALLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='ALL-cb'\n",
    "df.loc[(df['GEOL'].str.contains('BLDR', case = True))&(df['GEOL_DESC'].str.contains('ALLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='ALL-bd'\n",
    "\n",
    "## Colluvium (clay, fines, silt, sand, gravel, cbbl,boulder)\n",
    "df.loc[(df['GEOL'].str.contains('CLAY', case = True))&(df['GEOL_DESC'].str.contains('COLLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='COLL-c'\n",
    "df.loc[(df['GEOL'].str.contains('FINE', case = True))&(df['GEOL_DESC'].str.contains('COLLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='COLL-c/z'\n",
    "df.loc[(df['GEOL'].str.contains('SILT', case = True))&(df['GEOL_DESC'].str.contains('COLLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='COLL-z'\n",
    "df.loc[(df['GEOL'].str.contains('SAND', case = True))&(df['GEOL_DESC'].str.contains('COLLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='COLL-s'\n",
    "df.loc[(df['GEOL'].str.contains('GRAV', case = True))&(df['GEOL_DESC'].str.contains('COLLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='COLL-g'\n",
    "df.loc[(df['GEOL'].str.contains('CBBL', case = True))&(df['GEOL_DESC'].str.contains('COLLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='COLL-cb'\n",
    "df.loc[(df['GEOL'].str.contains('BLDR', case = True))&(df['GEOL_DESC'].str.contains('COLLUVIUM',\n",
    "                                                                                    case = True)),'Soil']='COLL-bd'\n",
    "\n",
    "## FILL (clay, silt, sand, gravel, cbbl,boulder)\n",
    "df.loc[(df['GEOL_DESC'].str.contains('CLAY', case = True))&(df['GEOL_DESC'].str.contains('FILL',\n",
    "                                                                                    case = True)),'Soil']='FILL-c'\n",
    "df.loc[(df['GEOL_DESC'].str.contains('SILT', case = True))&(df['GEOL_DESC'].str.contains('FILL',\n",
    "                                                                                    case = True)),'Soil']='FILL-z'\n",
    "df.loc[(df['GEOL_DESC'].str.contains('SAND', case = True))&(df['GEOL_DESC'].str.contains('FILL',\n",
    "                                                                                    case = True)),'Soil']='FILL-s'\n",
    "df.loc[(df['GEOL_DESC'].str.contains('GRAVEL', case = True))&(df['GEOL_DESC'].str.contains('FILL',\n",
    "                                                                                    case = True)),'Soil']='FILL-g'\n",
    "df.loc[(df['GEOL_DESC'].str.contains('COBBLE', case = True))&(df['GEOL_DESC'].str.contains('FILL',\n",
    "                                                                                    case = True)),'Soil']='FILL-cb'\n",
    "df.loc[(df['GEOL_DESC'].str.contains('BOULDER', case = True))&(df['GEOL_DESC'].str.contains('FILL',\n",
    "                                                                                    case = True)),'Soil']='FILL-bd'\n",
    "\n",
    "## Residual Soil(clay, silt, sand, gravel, cbbl,boulder)\n",
    "### Check once in GEOL & GEOL_DESC columns\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['GEOL_DESC'].str.contains('CLAY',case = True))|(df['GEOL'].str.contains(\n",
    "    'CLAY',case = True))),'Soil']='VI-c'\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['GEOL_DESC'].str.contains('SILT',case = True))|(df['GEOL'].str.contains(\n",
    "    'SILT',case = True))),'Soil']='VI-z'\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['GEOL_DESC'].str.contains('SAND',case = True))|(df['GEOL'].str.contains(\n",
    "    'SAND',case = True))),'Soil']='VI-s'\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['GEOL_DESC'].str.contains('GRAVEL',case = True))|(df['GEOL'].str.contains(\n",
    "    'GRAV',case = True))),'Soil']='VI-g'\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['GEOL_DESC'].str.contains('COBBLE',case = True))|(df['GEOL'].str.contains(\n",
    "    'CBBL',case = True))),'Soil']='VI-cb'\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['GEOL_DESC'].str.contains('BOULDER',case = True))|(df['GEOL'].str.contains(\n",
    "    'BLDR',case = True))),'Soil']='VI-bd'\n",
    "### Check once more in Details column\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['Details'].str.contains('CLAY',case = True))),'Soil']='VI-c'\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['Details'].str.contains('SILT',case = True))),'Soil']='VI-z'\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['Details'].str.contains('SAND',case = True))),'Soil']='VI-s'\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['Details'].str.contains('GRAVEL',case = True))),'Soil']='VI-g'\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['Details'].str.contains('COBBLE',case = True))),'Soil']='VI-cb'\n",
    "df.loc[(df['WETH_GRAD']=='VI')&((df['Details'].str.contains('BOUDLER',case = True))),'Soil']='VI-bl'\n",
    "\n",
    "## CDG (clay, silt, sand, gravel, cbbl,boulder)\n",
    "### Check once in GEOL & GEOL_DESC columns\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['GEOL_DESC'].str.contains('CLAY',case = True))|(df['GEOL'].str.contains(\n",
    "    'CLAY',case = True))),'Soil']='V-c'\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['GEOL_DESC'].str.contains('SILT',case = True))|(df['GEOL'].str.contains(\n",
    "    'SILT',case = True))),'Soil']='V-z'\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['GEOL_DESC'].str.contains('SAND',case = True))|(df['GEOL'].str.contains(\n",
    "    'SAND',case = True))),'Soil']='V-s'\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['GEOL_DESC'].str.contains('GRAVEL',case = True))|(df['GEOL'].str.contains(\n",
    "    'GRAV',case = True))),'Soil']='V-g'\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['GEOL_DESC'].str.contains('COBBLE',case = True))|(df['GEOL'].str.contains(\n",
    "    'CBBL',case = True))),'Soil']='V-cb'\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['GEOL_DESC'].str.contains('BOULDER',case = True))|(df['GEOL'].str.contains(\n",
    "    'BLDR',case = True))),'Soil']='V-bd'\n",
    "### Check once more in Details column\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['Details'].str.contains('CLAY',case = True))),'Soil']='V-c'\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['Details'].str.contains('SILT',case = True))),'Soil']='V-z'\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['Details'].str.contains('SAND',case = True))),'Soil']='V-s'\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['Details'].str.contains('GRAVEL',case = True))),'Soil']='V-g'\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['Details'].str.contains('COBBLE',case = True))),'Soil']='V-cb'\n",
    "df.loc[(df['WETH_GRAD']=='V')&((df['Details'].str.contains('BOUDLER',case = True))),'Soil']='V-bl'\n",
    "\n",
    "## HDG (clay, silt, sand, gravel, cbbl,boulder)\n",
    "### Check once in GEOL & GEOL_DESC columns\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['GEOL_DESC'].str.contains('CLAY',case = True))|(df['GEOL'].str.contains(\n",
    "    'CLAY',case = True))),'Soil']='IV-c'\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['GEOL_DESC'].str.contains('SILT',case = True))|(df['GEOL'].str.contains(\n",
    "    'SILT',case = True))),'Soil']='IV-z'\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['GEOL_DESC'].str.contains('SAND',case = True))|(df['GEOL'].str.contains(\n",
    "    'SAND',case = True))),'Soil']='IV-s'\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['GEOL_DESC'].str.contains('GRAVEL',case = True))|(df['GEOL'].str.contains(\n",
    "    'GRAV',case = True))),'Soil']='IV-g'\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['GEOL_DESC'].str.contains('COBBLE',case = True))|(df['GEOL'].str.contains(\n",
    "    'CBBL',case = True))),'Soil']='IV-cb'\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['GEOL_DESC'].str.contains('BOULDER',case = True))|(df['GEOL'].str.contains(\n",
    "    'BLDR',case = True))),'Soil']='IV-bd'\n",
    "### Check once more in Details column\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['Details'].str.contains('CLAY',case = True))),'Soil']='IV-c'\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['Details'].str.contains('SILT',case = True))),'Soil']='IV-z'\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['Details'].str.contains('SAND',case = True))),'Soil']='IV-s'\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['Details'].str.contains('GRAVEL',case = True))),'Soil']='IV-g'\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['Details'].str.contains('COBBLE',case = True))),'Soil']='IV-cb'\n",
    "df.loc[(df['WETH_GRAD']=='IV')&((df['Details'].str.contains('BOUDLER',case = True))),'Soil']='IV-bl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Step 3.3: Calculates Jn, Jr , Ja from RQD and descriptions\n",
    "'''\n",
    "\n",
    "# Define condition where Q calculation is valid:\n",
    "is_rock = (df['RQD'].notna())&(df['RQD']!=0)&(df['NR']==False)&(df['WETH_GRAD'].str.contains('V', case = True)==False)\n",
    "\n",
    "## Jn (from RQD)\n",
    "df.loc[(df['RQD']<25),'Jn']=15\n",
    "df.loc[((df['RQD']>=25)&(df['RQD']<75)),'Jn']=12\n",
    "df.loc[((df['RQD']>=75)&(df['RQD']<90)),'Jn']=9\n",
    "df.loc[((df['RQD']>=90)&(df['RQD']<=100)),'Jn']=6\n",
    "\n",
    "## Jr_Max, consider from lowest case first and overwrites\n",
    "### slickensided planar\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('slickensided', case = False))|(df['Details'].str.contains(\n",
    "    'slickensided',case = False)))&((df['GEOL_DESC'].str.contains('planar', case = False))|(df['Details'].str.contains(\n",
    "    'planar',case = False)))),'Jr_Max']=0.5\n",
    "### smooth planar\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('smooth', case = False))|(df['Details'].str.contains(\n",
    "    'smooth',case = False)))&((df['GEOL_DESC'].str.contains('planar', case = False))|(df['Details'].str.contains(\n",
    "    'planar',case = False)))),'Jr_Max']=1\n",
    "### rough planar\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('rough', case = False))|(df['Details'].str.contains(\n",
    "    'rough',case = False)))&((df['GEOL_DESC'].str.contains('planar', case = False))|(df['Details'].str.contains(\n",
    "    'planar',case = False)))),'Jr_Max']=1.5\n",
    "### slickensided undulating\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('slickensided', case = False))|(df['Details'].str.contains(\n",
    "    'slickensided',case = False)))&((df['GEOL_DESC'].str.contains('undulating', case = False))|(df['Details'].str.contains(\n",
    "    'undulating',case = False)))),'Jr_Max']=1.5\n",
    "### smooth undulating\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('smooth', case = False))|(df['Details'].str.contains(\n",
    "    'smooth',case = False)))&((df['GEOL_DESC'].str.contains('undulating', case = False))|(df['Details'].str.contains(\n",
    "    'undulating',case = False)))),'Jr_Max']=2\n",
    "### rough undulating\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('rough', case = False))|(df['Details'].str.contains(\n",
    "    'rough',case = False)))&((df['GEOL_DESC'].str.contains('undulating', case = False))|(df['Details'].str.contains(\n",
    "    'undulating',case = False)))),'Jr_Max']=3\n",
    "### rough/smooth/slickensided stepped\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('stepped', case = False))|(df['Details'].str.contains('stepped',\n",
    "                                                                                    case = False)))),'Jr_Max']=4\n",
    "\n",
    "## Jr_Min, consider in reverse order\n",
    "### rough/smooth/slickensided stepped\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('stepped', case = False))|(df['Details'].str.contains('stepped',\n",
    "                                                                                    case = False)))),'Jr_Min']=4\n",
    "### rough undulating\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('rough', case = False))|(df['Details'].str.contains(\n",
    "    'rough',case = False)))&((df['GEOL_DESC'].str.contains('undulating', case = False))|(df['Details'].str.contains(\n",
    "    'undulating',case = False)))),'Jr_Min']=3\n",
    "### smooth undulating\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('smooth', case = False))|(df['Details'].str.contains(\n",
    "    'smooth',case = False)))&((df['GEOL_DESC'].str.contains('undulating', case = False))|(df['Details'].str.contains(\n",
    "    'undulating',case = False)))),'Jr_Min']=2\n",
    "### slickensided undulating\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('slickensided', case = False))|(df['Details'].str.contains(\n",
    "    'slickensided',case = False)))&((df['GEOL_DESC'].str.contains('undulating', case = False))|(df['Details'].str.contains(\n",
    "    'undulating',case = False)))),'Jr_Min']=1.5\n",
    "### rough planar\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('rough', case = False))|(df['Details'].str.contains(\n",
    "    'rough',case = False)))&((df['GEOL_DESC'].str.contains('planar', case = False))|(df['Details'].str.contains(\n",
    "    'planar',case = False)))),'Jr_Min']=1.5\n",
    "### smooth planar\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('smooth', case = False))|(df['Details'].str.contains(\n",
    "    'smooth',case = False)))&((df['GEOL_DESC'].str.contains('planar', case = False))|(df['Details'].str.contains(\n",
    "    'planar',case = False)))),'Jr_Min']=1\n",
    "### slickensided planar\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('slickensided', case = False))|(df['Details'].str.contains(\n",
    "    'slickensided',case = False)))&((df['GEOL_DESC'].str.contains('planar', case = False))|(df['Details'].str.contains(\n",
    "    'planar',case = False)))),'Jr_Min']=0.5\n",
    "\n",
    "## Ja Max: consider from smallest up\n",
    "### Clean \n",
    "df.loc[is_rock&((df['GEOL_DESC'].str.contains('clean', case = False))|(df['Details'].str.contains('clean',case = False))),\n",
    "       'Ja_Max']=1\n",
    "### Iron / Manganese Staining\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('iron', case = False))|(df['Details'].str.contains('iron',case = False))|\n",
    "       (df['GEOL_DESC'].str.contains('manganese',case = False))|(df['Details'].str.contains('manganese',case = False))|\n",
    "       (df['GEOL_DESC'].str.contains('stain',case = False))|(df['Details'].str.contains('stain',case = False)))),\n",
    "       'Ja_Max']=1.5\n",
    "### Sand infill\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('sand', case = False))|(df['Details'].str.contains('sand',case = False)))),\n",
    "       'Ja_Max']=2\n",
    "### Clay infill\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('clay', case = False))|(df['Details'].str.contains('clay',case = False))|\n",
    "                (df['GEOL_DESC'].str.contains('quartz infill',case = False))|(df['Details'].str.contains('quartz infill',\n",
    "                                                                                                    case = False))\n",
    "                )),'Ja_Max']=3\n",
    "### Kaolin / chlorite\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('kaolin', case = False))|(df['Details'].str.contains('kaolin',case = False))|\n",
    "       (df['GEOL_DESC'].str.contains('chlorite',case = False))|(df['Details'].str.contains('chlorite',case = False))|\n",
    "                (df['GEOL_DESC'].str.contains('calcite coated',case = False))|(df['Details'].str.contains('calcite coated',\n",
    "                                                                                                    case = False)))),\n",
    "       'Ja_Max']=4\n",
    "\n",
    "## Ja Min: consider from biggest down\n",
    "### Kaolin / chlorite\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('kaolin', case = False))|(df['Details'].str.contains('kaolin',case = False))|\n",
    "       (df['GEOL_DESC'].str.contains('chlorite',case = False))|(df['Details'].str.contains('chlorite',case = False)))),\n",
    "       'Ja_Min']=4\n",
    "### Clay infill\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('clay', case = False))|(df['Details'].str.contains('clay',case = False)))),\n",
    "       'Ja_Min']=3\n",
    "### Sand infill\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('sand', case = False))|(df['Details'].str.contains('sand',case = False))|\n",
    "                (df['GEOL_DESC'].str.contains('calcite coated',case = False))|(df['Details'].str.contains('calcite coated',\n",
    "                                                                                                          case = False))|\n",
    "                (df['GEOL_DESC'].str.contains('quartz infill',case = False))|(df['Details'].str.contains('quartz infill',\n",
    "                                                                                                         case = False))\n",
    "                )),'Ja_Min']=2\n",
    "### Iron / Manganese Staining\n",
    "df.loc[(is_rock&((df['GEOL_DESC'].str.contains('iron', case = False))|(df['Details'].str.contains('iron',case = False))|\n",
    "       (df['GEOL_DESC'].str.contains('manganese',case = False))|(df['Details'].str.contains('manganese',case = False))|\n",
    "       (df['GEOL_DESC'].str.contains('stain',case = False))|(df['Details'].str.contains('stain',case = False)))),\n",
    "       'Ja_Min']=1.5\n",
    "### Clean \n",
    "df.loc[is_rock&((df['GEOL_DESC'].str.contains('clean', case = False))|(df['Details'].str.contains('clean',case = False))),\n",
    "       'Ja_Min']=1\n",
    "\n",
    "#Step 3.4: Calculates Q'\n",
    "df['Jw']=''\n",
    "df['SRF']=''\n",
    "df[\"Q'\"]=((df['RQD']/df['Jn'])*(df['Jr_Min']/df['Ja_Max']))\n",
    "df['Q']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.head()\n",
    "import datetime\n",
    "time_now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "df.to_excel('concat_processed_{}.xlsx'.format(time_now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# Wash boring \n",
    "WB_list = ['WASHING','Wash boring', 'wash boring', 'Wash-boring', 'wash-boring', \n",
    "           'Wash-drilling', 'wash-drilling', 'Wash drilling', 'WASH BORING']\n",
    "\n",
    "washing = ((df[\"Details\"].str.contains('|'.join(WB_list))) | \n",
    "           (df[\"GEOL_DESC\"].str.contains('|'.join(WB_list))))\n",
    "\n",
    "df.loc[washing, 'Material'] = 'Wash boring'\n",
    "\n",
    "\n",
    "# Transported vs in situ\n",
    "transported = df[\"WETH_GRAD\"].isna()\n",
    "df.loc[(~washing)&transported, 'Material'] = 'Transported'\n",
    "df.loc[(~washing)&(~transported), 'Material'] = 'In situ'\n",
    "\n",
    "# Further check if some are simply missing the weathering grade \n",
    "# - assume everything down an insitt intervals are in situ (applies for vertical / steep inclined BH)\n",
    "transported = df['Material']=='Transported'\n",
    "insitu = df['Material']=='In situ'\n",
    "\n",
    "for BH in HOLE_ID:\n",
    "    sel = df['HOLE_ID']==BH\n",
    "    # the first in situ \"From\" level\n",
    "    try:\n",
    "        BH_insitu_level = df.loc[sel & insitu, 'DEPTH_FROM'].iloc[0]\n",
    "        insitu_below = df['DEPTH_FROM'] > BH_insitu_level\n",
    "        df.loc[sel & transported & insitu_below , 'Material'] = 'In situ'\n",
    "    except IndexError: # Cases without  insitu material in the BH\n",
    "        pass\n",
    "\n",
    "# Lithology & Label\n",
    "\n",
    "# Method 1: Using re.search() with end of string anchor $\n",
    "def extract_last_bracket1(text):\n",
    "    try:\n",
    "        matches = re.findall(r'\\((.*?)\\)', text)\n",
    "        return matches[-1] if matches else None\n",
    "    except TypeError: # Empty description \n",
    "        pass\n",
    "    \n",
    "def extract_capitals(text):\n",
    "    # First remove content in brackets\n",
    "    try:\n",
    "        text_without_brackets = re.sub(r'\\([^)]*\\)', '', text)\n",
    "        # Remove the first character\n",
    "        text_without_first = text_without_brackets[1:]\n",
    "        # Find sequences of capital letters\n",
    "        capitals = re.findall(r'[A-Z]+', text_without_first)\n",
    "        if len(capitals)==0:\n",
    "            capitals = \"\"\n",
    "        elif len(capitals)==1:\n",
    "            capitals = capitals[0]\n",
    "        else:\n",
    "            capitals = \" & \".join(capitals)\n",
    "        return capitals\n",
    "    except TypeError: # Empty description \n",
    "        pass\n",
    "    \n",
    "transported = df['Material']=='Transported'\n",
    "\n",
    "df.loc[transported, 'LITH'] = df.loc[transported, 'GEOL_DESC'].apply(extract_last_bracket1)\n",
    "df.loc[transported, 'PRIMARY'] = df.loc[transported, 'GEOL_DESC'].apply(extract_capitals)\n",
    "df['CAPITALS'] = df['GEOL_DESC'].apply(extract_capitals)\n",
    "\n",
    "# Wash-bored & In situ material\n",
    "df.loc[washing, 'LITH'] = 'WASHING'\n",
    "df.loc[df['Material']==\"In situ\", 'LITH'] = df.loc[df['Material']==\"In situ\", 'WETH_GRAD']\n",
    "\n",
    "df.to_excel('Intervals.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
